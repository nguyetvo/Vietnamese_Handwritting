{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Training] RCNN_CTC_Vietnamese_Address.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "764Jwuqdpt4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "27513669-0deb-43d2-88d2-9bcf58818ded"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OPN2mZb_p2Cv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('drive/My Drive/Machine_Learning-prj/vietnamese_address/images_64_1595.pkl', 'rb') as f:\n",
        "    images = pickle.load(f)\n",
        "    \n",
        "with open('drive/My Drive/Machine_Learning-prj/vietnamese_address/scripts_64_1595.pkl', 'rb') as f:\n",
        "    scripts = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJGLsNh18-NQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# with open('drive/My Drive/Machine_Learning-prj/vietnamese_address/images_address.pkl', 'rb') as f:\n",
        "#     images = pickle.load(f)\n",
        "    \n",
        "# with open('drive/My Drive/Machine_Learning-prj/vietnamese_address/scripts_address.pkl', 'rb') as f:\n",
        "#     scripts = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUHv_gIxp_8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6c9f1d17-5ce2-4b05-fdaf-9b26d069ffb5"
      },
      "cell_type": "code",
      "source": [
        "print(len(images), len(scripts))\n",
        "images = images[:7200]\n",
        "scripts = scripts[:7200]\n",
        "len(images), len(scripts)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7260 7260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7200, 7200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9FZ9SNu-ZDf0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def scale(img, scale_prob = 0.5, scale_stdv = 0.12):\n",
        "    \"\"\"\n",
        "    It scale the image provided to a random size chosen from the sample of a lognormal probability\n",
        "    function with scale_stdv standard deviation. The probabilite that the image will be scaled is scale_prob.\n",
        "    \n",
        "    Args:\n",
        "        img: numpy format image.\n",
        "        scale_prob: probability of scaling the image.\n",
        "        scale_stdv: standard deviation of the lognormal probability function used to chose\n",
        "            the size of the scaled image.\n",
        "            \n",
        "    Returns:\n",
        "        img: the scaled (or not) image.\n",
        "    \n",
        "    \"\"\"\n",
        "    scale = np.random.binomial(1, scale_prob)\n",
        "    \n",
        "    if scale:\n",
        "        \n",
        "        imgPIL = Image.fromarray(img)\n",
        "        ho, vo = imgPIL.size\n",
        "        scale_factor = np.random.lognormal(sigma=scale_stdv)\n",
        "        hn, vn = int(scale_factor*ho), int(scale_factor*vo)\n",
        "        img_sc = imgPIL.resize((hn, vn))\n",
        "        \n",
        "        img = np.array(img_sc).reshape((vn,hn))\n",
        "                \n",
        "        if hn > ho:\n",
        "            img = img[int(vn/2)-int(vo/2):int(vn/2)+int(np.ceil(vo/2)) ,int(hn/2)-int(ho/2):int(hn/2)+int(np.ceil(ho/2))] \n",
        "        else:\n",
        "            img = np.pad(img, ((int((vo-vn)/2), int(np.ceil((vo-vn)/2))),((int((ho-hn)/2), int(np.ceil((ho-hn)/2))))), mode='constant')\n",
        "            \n",
        "    return img\n",
        "\n",
        "def shear(img, shear_prob = 0.5, shear_prec = 4):\n",
        "    \"\"\"\n",
        "    It shear the image provided to a random angle chosen from the sample of a vonmises probability\n",
        "    function with shear_prec kappa parameter. The probability that the image will be sheared is shear_prob.\n",
        "    \n",
        "    Args:\n",
        "        img: numpy format image.\n",
        "        shear_prob: probability of shearing the image.\n",
        "        shear_prec: kappa parameter of the vonmises probability function used to chose\n",
        "            the angle to shear image.\n",
        "            \n",
        "    Returns:\n",
        "        img: the sheared (or not) image.\n",
        "    \n",
        "    \"\"\"\n",
        "    shear = np.random.binomial(1, shear_prob)\n",
        "\n",
        "    if shear:\n",
        "        import cv2\n",
        "        rows,cols = img.shape\n",
        "        shear_angle = np.random.vonmises(0, kappa = shear_prec)\n",
        "        m = np.tan(shear_angle)\n",
        "        \n",
        "        pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
        "        pts2 = np.float32([[50,50],[200,50],[50+m*150,200]])\n",
        "        M = cv2.getAffineTransform(pts1,pts2)\n",
        "            \n",
        "        img = cv2.warpAffine(img,M,(cols,rows))\n",
        "        \n",
        "    return img\n",
        "\n",
        "def rotate(img, rotate_prob = 0.5, rotate_prec = 100):\n",
        "    \"\"\"\n",
        "    It rotate the image provided to a random angle chosen from the sample of a vonmises probability\n",
        "    function with rotate_prec kappa parameter. The probability that the image will be sheared is rotate_prob.\n",
        "    \n",
        "    Args:\n",
        "        img: numpy format image.\n",
        "        rotate_prob: probability of rotating the image.\n",
        "        rotate_prec: kappa parameter of the vonmises probability function used to chose\n",
        "            the angle to rotate image.\n",
        "            \n",
        "    Returns:\n",
        "        img: the rotated (or not) image.\n",
        "    \n",
        "    \"\"\"    \n",
        "    rotate = np.random.binomial(1, rotate_prob)\n",
        "    \n",
        "    if rotate:\n",
        "        import cv2\n",
        "        rows,cols = img.shape\n",
        "        rotate_prec = rotate_prec * max(rows/cols, cols/rows)\n",
        "        rotate_angle = np.random.vonmises(0, kappa = rotate_prec)*180/np.pi\n",
        "        M = cv2.getRotationMatrix2D((cols/2,rows/2),rotate_angle,1)\n",
        "        img = cv2.warpAffine(img,M,(cols,rows))\n",
        "    \n",
        "    return img\n",
        "\n",
        "def translate(img, translate_prob = 0.5, translate_stdv = 0.02):\n",
        "    \"\"\"\n",
        "    It translate the image provided to a random position chosen from the sample of a normal probability\n",
        "    function with translate_stdv standard deviation. The probability that the image will be translated is tanslate_prob.\n",
        "    \n",
        "    Args:\n",
        "        img: numpy format image.\n",
        "        translate_prob: probability of translating the image.\n",
        "        translate_stdv: standard deviation of the normal probability function used to chose\n",
        "            the position to translate the image.\n",
        "            \n",
        "    Returns:\n",
        "        img: the translated (or not) image.\n",
        "    \n",
        "    \"\"\"\n",
        "    translate = np.random.binomial(1, translate_prob)\n",
        "    \n",
        "    if translate:\n",
        "        import cv2\n",
        "        rows,cols = img.shape\n",
        "        h_translation_factor = np.random.normal(0, scale = translate_stdv * cols)\n",
        "        v_translation_factor = np.random.normal(0, scale = translate_stdv * rows)\n",
        "        M = np.float32([[1,0,h_translation_factor],[0,1,v_translation_factor]])\n",
        "        img = cv2.warpAffine(img,M,(cols,rows))\n",
        "    \n",
        "    return img\n",
        "\n",
        "def dilate(img, dilation_prob = 0.5 , dilation_srate = 0.4, dilation_rrate = 1):\n",
        "    \n",
        "    dilate = np.random.binomial(1, dilation_prob)\n",
        "    \n",
        "    if dilate:\n",
        "        import cv2\n",
        "        kernel_size = np.min([2*np.random.geometric(dilation_srate)+1, 15])\n",
        "        kernel = np.zeros([kernel_size, kernel_size])\n",
        "        center = np.array([int(kernel_size/2), int(kernel_size/2)])\n",
        "        for x in range(kernel_size):\n",
        "            for y in range(kernel_size):\n",
        "                d = np.linalg.norm(np.array([x,y])-center)\n",
        "                p = np.exp(-d*1)\n",
        "                value = np.random.binomial(1, p)\n",
        "                kernel[x,y] = value or 10**-16\n",
        "        \n",
        "        img = cv2.dilate(img,kernel,iterations = 1)\n",
        "    \n",
        "    return img\n",
        "\n",
        "def erode(img, erosion_prob = 0.5 , erosion_srate = 0.8, erosion_rrate = 1.2):\n",
        "    \n",
        "    erode = np.random.binomial(1, erosion_prob)\n",
        "    \n",
        "    if erode:\n",
        "        import cv2\n",
        "        kernel_size = np.min([2*np.random.geometric(erosion_srate)+1, 15])\n",
        "        kernel = np.zeros([kernel_size, kernel_size])\n",
        "        center = np.array([int(kernel_size/2), int(kernel_size/2)])\n",
        "        for x in range(kernel_size):\n",
        "            for y in range(kernel_size):\n",
        "                d = np.linalg.norm(np.array([x,y])-center)\n",
        "                p = np.exp(-d*1)\n",
        "                value = np.random.binomial(1, p)\n",
        "                kernel[x,y] = value or 10**-16\n",
        "        \n",
        "        img = cv2.erode(img,kernel,iterations = 1)\n",
        "    \n",
        "    return img\n",
        "\n",
        "def distort(img_list):\n",
        "    new_list=[]\n",
        "    for ind, img_np in enumerate(img_list):\n",
        "        #img_np = 255 - img_np\n",
        "        img_np = translate(img_np)\n",
        "        img_np = rotate(img_np)\n",
        "        img_np = shear(img_np)\n",
        "        img_np = scale(img_np)\n",
        "        img_np = dilate(img_np)\n",
        "        img_np = erode(img_np)\n",
        "        new_list.append(img_np)\n",
        "    \n",
        "    return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NadanKIFfni-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d31e200a-181e-41dc-8184-8eb3908f2c10"
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "images_augumented = []\n",
        "scripts_augumented = []\n",
        "\n",
        "for i, img in tqdm(enumerate(images)):\n",
        "    images_augumented.append(img)\n",
        "    scripts_augumented.append(scripts[i])\n",
        "    \n",
        "    for k in range(3):\n",
        "        img_tmp = translate(img)\n",
        "        img_tmp = rotate(img_tmp)\n",
        "        img_tmp = shear(img_tmp)\n",
        "        img_tmp = scale(img_tmp)\n",
        "        img_tmp = dilate(img_tmp)\n",
        "        img_tmp = erode(img_tmp)\n",
        "        images_augumented.append(img_tmp)\n",
        "        scripts_augumented.append(scripts[i])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7200it [00:36, 195.97it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0-W3Xv6TgxLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d976198b-614c-4a43-c708-68d4e79d367b"
      },
      "cell_type": "code",
      "source": [
        "len(images_augumented),  len(scripts_augumented)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28800, 28800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "d0bx8G8SgsR7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del images\n",
        "del scripts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JC_JOZfJqp94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alphabet = u'\\ !%\"#&\\'()*+,-./0123456789:;?AÁẢÀÃẠÂẤẨẦẪẬĂẮẲẰẴẶBCDĐEÉẺÈẼẸÊẾỂỀỄỆFGHIÍỈÌĨỊJKLMNOÓỎÒÕỌÔỐỔỒỖỘƠỚỞỜỠỢPQRSTUÚỦÙŨỤƯỨỬỪỮỰVWXYÝỶỲỸỴZaáảàãạâấẩầẫậăắẳằẵặbcdđeéẻèẽẹêếểềễệfghiíỉìĩịjklmnoóỏòõọôốổồỗộơớởờỡợpqrstuúủùũụưứửừữựvwxyýỷỳỹỵz'\n",
        "\n",
        "def text_to_labels(text):\n",
        "    ret = []\n",
        "    for char in text:\n",
        "        ret.append(alphabet.find(char))\n",
        "    return ret\n",
        "\n",
        "\n",
        "# Reverse translation of numerical classes back to characters\n",
        "def labels_to_text(labels):\n",
        "    ret = []\n",
        "    for c in labels:\n",
        "        if c == len(alphabet):  # CTC Blank\n",
        "            ret.append(\"\")\n",
        "        else:\n",
        "            ret.append(alphabet[c])\n",
        "    return \"\".join(ret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1BBoO822Crpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5df265d6-d33c-432f-efb0-8414af72af7e"
      },
      "cell_type": "code",
      "source": [
        "len(alphabet)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "7-1eRR8TnIVd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train_len = np.ones((len(images_augumented), 1), dtype=np.float32) * 254\n",
        "y_train_len = np.asarray([len(scripts_augumented[i]) for i in range(len(scripts_augumented))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVKkzXaBokQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels_script = [text_to_labels(s) for s in scripts_augumented]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "utTulLhPnpxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6ea7373a-da2e-48b1-ca77-6f4c2bd04735"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "# images = sequence.pad_sequences(images, value=255, dtype='uint8',\n",
        "                                         #padding=\"post\", truncating='post')\n",
        "labels_script = sequence.pad_sequences(labels_script, value=len(alphabet), maxlen=256,\n",
        "                                         dtype=\"float32\", padding=\"post\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZNY3RMYItYph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "91cd0550-9539-4011-9303-230f721a3417"
      },
      "cell_type": "code",
      "source": [
        "y_train_len.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28800,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "lHShwKudqBrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Building model\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, GRU, Dense, Input, Add, Concatenate, Reshape, Lambda\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAzpqgEc9UA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN\n",
        "    # tend to be garbage:\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "npcKfSWtjhNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocessing_image(image):\n",
        "    image = image/255.\n",
        "    image = cv2.copyMakeBorder(image, 0, 0, 0, 1595 - image.shape[1] ,cv2.BORDER_CONSTANT,value=0)\n",
        "    image = np.reshape(image, (64, 1595, 1))\n",
        "    image = image.transpose((1, 0, 2)) \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBtD0GxQuDmT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_batch_generator(images, labels, x_train_len, y_train_len, batch_size):\n",
        "    while True:\n",
        "        # Select files (paths/indices) for the batch\n",
        "        batch_paths = np.random.choice(a = len(images), size = batch_size)\n",
        "        input = []\n",
        "        output = []\n",
        "        input_len = []\n",
        "        output_len = []\n",
        "        \n",
        "        # Read in each input, perform preprocessing and get labels\n",
        "        for i in batch_paths:\n",
        "            input.append(preprocessing_image(image=images[i]))\n",
        "            output.append(labels[i])\n",
        "            input_len.append(x_train_len[i])\n",
        "            output_len.append(y_train_len[i])\n",
        "        input = np.array(input)\n",
        "        output = np.array(output)\n",
        "        input_len = np.array(input_len)\n",
        "        output_len = np.array(output_len)\n",
        "    \n",
        "        # Return a tuple of (input,output) to feed the network\n",
        "        \n",
        "        yield( [input, output, input_len, output_len], np.zeros(len(input)) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mjllrWVa1oEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "6470dce3-c8a8-4cc6-eb68-16c29c385f78"
      },
      "cell_type": "code",
      "source": [
        "img_w = 1595\n",
        "# Input Parameters\n",
        "img_h = 64\n",
        "# Network parameters\n",
        "conv_filters = 16\n",
        "kernel_size = (3, 3)\n",
        "pool_size = 2\n",
        "time_dense_size = 256\n",
        "rnn_size = 256\n",
        "minibatch_size = 32\n",
        "unique_tokens = 216\n",
        "\n",
        " \n",
        "input_shape = (img_w, img_h, 1)\n",
        "\n",
        "act = 'relu'\n",
        "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
        "\n",
        "inner = Conv2D(64, 3, padding='same', activation=act,name='conv1', kernel_initializer='he_normal')(input_data)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
        "inner = Conv2D(128, 3, padding='same',activation=act, name='conv2', kernel_initializer='he_normal')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
        "inner = Conv2D(256, 3, padding='same',activation=act, name='conv3', kernel_initializer='he_normal')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max3')(inner)\n",
        "\n",
        "conv_to_rnn_dims = (256, 199*8)\n",
        "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
        "\n",
        "# cuts down input size going into RNN:\n",
        "inner = Dense(time_dense_size, activation=act, kernel_initializer='he_normal', name='dense1')(inner)\n",
        "\n",
        "# Two layers of bidirectional GRUs\n",
        "# GRU seems to work as well, if not better than LSTM:\n",
        "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
        "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
        "gru1_merged = Add()([gru_1, gru_1b])\n",
        "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "gru_2b = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', go_backwards=True, name='gru2_b')(gru1_merged)\n",
        "\n",
        "# transforms RNN output to character activations:\n",
        "inner = Dense(unique_tokens,name='dense2')(Concatenate()([gru_2, gru_2b]))\n",
        "y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "# #Get text predict\n",
        "# out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0])*y_pred.shape[1],\n",
        "#                          greedy=True)[0][0])\n",
        "\n",
        "Model(inputs=input_data, outputs=y_pred).summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          (None, 1595, 64, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 1595, 64, 64) 640         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 797, 32, 64)  0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 797, 32, 128) 73856       max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 398, 16, 128) 0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 398, 16, 256) 295168      max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max3 (MaxPooling2D)             (None, 199, 8, 256)  0           conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 256, 1592)    0           max3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 256, 256)     407808      reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (GRU)                      (None, 256, 256)     393984      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (GRU)                    (None, 256, 256)     393984      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256, 256)     0           gru1[0][0]                       \n",
            "                                                                 gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (GRU)                      (None, 256, 256)     393984      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (GRU)                    (None, 256, 256)     393984      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256, 512)     0           gru2[0][0]                       \n",
            "                                                                 gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 256, 216)     110808      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 256, 216)     0           dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,464,216\n",
            "Trainable params: 2,464,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xnOoSebE7Gg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = Input(name='the_labels', shape=[256, ], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "# Keras doesn't currently support loss funcs with extra parameters\n",
        "# so CTC loss is implemented in a lambda layer\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "# clipnorm seems to speeds up convergence\n",
        "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "# rms = RMSprop(lr=0.001, clipnorm=5, clipvalue=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_NNNyqo6LOD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = Model(inputs=input_data, outputs=y_pred)\n",
        "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CslcJpUs-UI6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vy9Rq1E67CRZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1043
        },
        "outputId": "303bf259-dcb2-4e43-c0c3-7f87fdd95292"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          (None, 1595, 64, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 1595, 64, 64) 640         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 797, 32, 64)  0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 797, 32, 128) 73856       max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 398, 16, 128) 0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 398, 16, 256) 295168      max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max3 (MaxPooling2D)             (None, 199, 8, 256)  0           conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 256, 1592)    0           max3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 256, 256)     407808      reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (GRU)                      (None, 256, 256)     393984      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (GRU)                    (None, 256, 256)     393984      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256, 256)     0           gru1[0][0]                       \n",
            "                                                                 gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (GRU)                      (None, 256, 256)     393984      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (GRU)                    (None, 256, 256)     393984      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256, 512)     0           gru2[0][0]                       \n",
            "                                                                 gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 256, 216)     110808      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 256, 216)     0           dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 input_length[0][0]               \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,464,216\n",
            "Trainable params: 2,464,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZVgFPN4MSjYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "10f5a188-06c1-4d5e-a843-387ff978a60a"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "print(\"Loading pre-trained weight\")\n",
        "model.load_weights('drive/My Drive/Machine_Learning-prj/vietnamese_address/weight/20xaugument-weights-training-improvement-05-82.40.hdf5')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pre-trained weight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GXeW3lr4RcKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = 'drive/My Drive/Machine_Learning-prj/vietnamese_address/weight/3xaugument-weights-training-improvement-{epoch:02d}-{val_loss:.2f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4udql0dcT-5I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_idx = 28000\n",
        "test_idx = 28600\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pj__Vq7Ugcje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.fit([images, labels_script, x_train_len, y_train_len], np.zeros(len(images)), validation_split=0.01 ,batch_size=16, epochs=200, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z38RwnAHwguK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2212
        },
        "outputId": "c43b2390-40cc-469c-a2d8-ec62b731a2f3"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator=image_batch_generator(images_augumented[:train_idx], labels_script[:train_idx], x_train_len[:train_idx], y_train_len[:train_idx], batch_size), steps_per_epoch=(len(images_augumented[:train_idx])//batch_size) , epochs=200, verbose=1, callbacks=callbacks_list, \n",
        "                    validation_data=image_batch_generator(images_augumented[train_idx:], labels_script[train_idx:], x_train_len[train_idx:], y_train_len[train_idx:], batch_size), validation_steps=(len(images_augumented[train_idx:])//batch_size))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Epoch 1/200\n",
            "437/437 [==============================] - 1414s 3s/step - loss: 67.3695 - val_loss: 71.1530\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 71.15297, saving model to drive/My Drive/Machine_Learning-prj/vietnamese_address/weight/3xaugument-weights-training-improvement-01-71.15.hdf5\n",
            "Epoch 2/200\n",
            "437/437 [==============================] - 1401s 3s/step - loss: 64.1026 - val_loss: 78.3943\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 71.15297\n",
            "Epoch 3/200\n",
            "437/437 [==============================] - 1381s 3s/step - loss: 61.5572 - val_loss: 73.0867\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 71.15297\n",
            "Epoch 4/200\n",
            "437/437 [==============================] - 1388s 3s/step - loss: 59.5838 - val_loss: 72.1636\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 71.15297\n",
            "Epoch 5/200\n",
            "437/437 [==============================] - 1364s 3s/step - loss: 58.2314 - val_loss: 66.8427\n",
            "\n",
            "Epoch 00005: val_loss improved from 71.15297 to 66.84275, saving model to drive/My Drive/Machine_Learning-prj/vietnamese_address/weight/3xaugument-weights-training-improvement-05-66.84.hdf5\n",
            "Epoch 6/200\n",
            "437/437 [==============================] - 1386s 3s/step - loss: 56.7048 - val_loss: 71.3677\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 66.84275\n",
            "Epoch 7/200\n",
            "437/437 [==============================] - 1369s 3s/step - loss: 55.8440 - val_loss: 69.9593\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 66.84275\n",
            "Epoch 8/200\n",
            "437/437 [==============================] - 1375s 3s/step - loss: 54.7297 - val_loss: 73.8219\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 66.84275\n",
            "Epoch 9/200\n",
            " 19/437 [>.............................] - ETA: 21:35 - loss: 55.3756"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bbded56096c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(generator=image_batch_generator(images_augumented[:train_idx], labels_script[:train_idx], x_train_len[:train_idx], y_train_len[:train_idx], batch_size), steps_per_epoch=(len(images_augumented[:train_idx])//batch_size) , epochs=200, verbose=1, callbacks=callbacks_list, \n\u001b[0;32m----> 2\u001b[0;31m                     validation_data=image_batch_generator(images_augumented[train_idx:], labels_script[train_idx:], x_train_len[train_idx:], y_train_len[train_idx:], batch_size), validation_steps=(len(images_augumented[train_idx:])//batch_size))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sefGyGqL-Qp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "87a67610-73ad-4e34-e8c8-6ac969e4dc57"
      },
      "cell_type": "code",
      "source": [
        "model.input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'the_input:0' shape=(?, 32, 256, 1) dtype=float32>,\n",
              " <tf.Tensor 'the_labels_1:0' shape=(?, ?) dtype=float32>,\n",
              " <tf.Tensor 'input_length_1:0' shape=(?, 1) dtype=int64>,\n",
              " <tf.Tensor 'label_length_1:0' shape=(?, 1) dtype=int64>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "MLiF9I9IDq4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "145ca58a-a2ca-42aa-b2be-cacfb062abd8"
      },
      "cell_type": "code",
      "source": [
        "model.output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'ctc_2/ExpandDims:0' shape=(?, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "vzxLVhrWNGvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9a681df3-0106-4a91-cc7b-17d1cfb30075"
      },
      "cell_type": "code",
      "source": [
        "loss_out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'ctc/ExpandDims:0' shape=(?, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "878qoEnRYcyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('drive/My Drive/Machine_Learning-prj/sentence_hand_written/model_weight.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zx3hdHHpfA_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "46f1ca70-e836-4d47-b47f-d86957df9c96"
      },
      "cell_type": "code",
      "source": [
        "np.where(labels_script < 0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "p8gsZ_zewb46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}